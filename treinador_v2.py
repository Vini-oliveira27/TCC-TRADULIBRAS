#!/usr/bin/env python3
"""
TREINADOR LIBRAS - COMPATÃVEL COM APP.PY
Treinador otimizado para o sistema TraduLibras
"""

import pandas as pd
import numpy as np
import pickle
import os
import glob
import json
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

class TreinadorLIBRAS:
    def __init__(self):
        self.modelo = None
        self.scaler = None
        self.encoder = None
        self.info_modelo = {}
        
        # ConfiguraÃ§Ãµes do modelo
        self.config = {
            'test_size': 0.2,
            'random_state': 42,
            'n_estimators': 200,
            'max_depth': 20,
            'min_samples_split': 3,
            'min_samples_leaf': 1,
            'cv_folds': 5
        }
        
    def encontrar_dataset(self):
        """Encontrar o dataset mais recente"""
        possiveis_caminhos = [
            'dados_libras/dataset_libras.csv',
            'dados_libras/gestos.csv', 
            'dataset_libras.csv',
            'gestos.csv'
        ]
        
        for caminho in possiveis_caminhos:
            if os.path.exists(caminho):
                return caminho
        
        # Buscar qualquer CSV
        arquivos_csv = glob.glob('**/*.csv', recursive=True)
        if arquivos_csv:
            return max(arquivos_csv, key=os.path.getctime)
        
        return None
    
    def diagnosticar_dataset(self, arquivo):
        """DiagnÃ³stico completo do dataset"""
        print("ğŸ” DIAGNÃ“STICO DO DATASET")
        print("=" * 60)
        
        if not arquivo or not os.path.exists(arquivo):
            print("âŒ Nenhum dataset encontrado!")
            print("ğŸ’¡ Execute primeiro: python coletor_libras.py")
            return False
        
        try:
            df = pd.read_csv(arquivo)
            
            # Verificar estrutura bÃ¡sica
            num_features = len(df.columns) - 1
            num_amostras = len(df)
            classes = df['classe'].unique()
            
            print(f"ğŸ“ Arquivo: {arquivo}")
            print(f"ğŸ“Š Total de amostras: {num_amostras:,}")
            print(f"ğŸ”§ Features por amostra: {num_features}")
            print(f"ğŸ¯ Classes detectadas: {list(classes)}")
            
            # Verificar compatibilidade
            if num_features != 51:
                print(f"âŒ INCOMPATÃVEL: Esperado 51 features, encontrado {num_features}")
                print("ğŸ’¡ Use o coletor_libras.py para gerar dados compatÃ­veis")
                return False
            
            print("âœ… COMPATÃVEL: 51 features detectadas")
            
            # AnÃ¡lise de distribuiÃ§Ã£o
            print("\nğŸ“ˆ DISTRIBUIÃ‡ÃƒO DAS CLASSES:")
            distribuiÃ§Ã£o = df['classe'].value_counts()
            for classe, count in distribuiÃ§Ã£o.items():
                percentual = (count / num_amostras) * 100
                print(f"   {classe:>8}: {count:>4} amostras ({percentual:5.1f}%)")
            
            # Verificar balanceamento
            min_amostras = distribuiÃ§Ã£o.min()
            max_amostras = distribuiÃ§Ã£o.max()
            ratio = max_amostras / min_amostras if min_amostras > 0 else float('inf')
            
            print(f"\nâš–ï¸  BALANCEAMENTO:")
            print(f"   MÃ­nimo: {min_amostras} amostras")
            print(f"   MÃ¡ximo: {max_amostras} amostras") 
            print(f"   RazÃ£o: {ratio:.1f}x")
            
            if ratio > 5:
                print("âš ï¸  ALERTA: Dataset muito desbalanceado!")
            elif ratio > 3:
                print("âš ï¸  AVISO: Dataset desbalanceado")
            else:
                print("âœ… Dataset balanceado")
            
            # Verificar qualidade dos dados
            print(f"\nğŸ” QUALIDADE DOS DADOS:")
            nulos = df.isnull().sum().sum()
            print(f"   Valores nulos: {nulos}")
            
            if nulos > 0:
                print("âš ï¸  AVISO: Valores nulos detectados")
                df = df.dropna()
                print(f"   Amostras apÃ³s limpeza: {len(df):,}")
            
            # Salvar informaÃ§Ãµes
            self.info_dataset = {
                'arquivo': arquivo,
                'amostras': len(df),
                'features': num_features,
                'classes': list(classes),
                'distribuicao': distribuiÃ§Ã£o.to_dict(),
                'balanceamento_ratio': ratio,
                'compativel': True
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ Erro no diagnÃ³stico: {e}")
            return False
    
    def preparar_dados(self):
        """Preparar dados para treinamento"""
        print("\nğŸ”§ PREPARANDO DADOS PARA TREINAMENTO")
        print("=" * 60)
        
        if not hasattr(self, 'info_dataset') or not self.info_dataset['compativel']:
            print("âŒ Dataset incompatÃ­vel")
            return None
        
        try:
            df = pd.read_csv(self.info_dataset['arquivo'])
            
            # Limpar dados nulos
            df = df.dropna()
            
            # Separar features e labels
            X = df.iloc[:, 1:].values  # Features (colunas 1-51)
            y = df.iloc[:, 0].values   # Labels (coluna 0 - classe)
            
            print(f"ğŸ“¦ Dados carregados:")
            print(f"   - Features (X): {X.shape}")
            print(f"   - Labels (y): {y.shape}")
            
            # Codificar labels
            self.encoder = LabelEncoder()
            y_encoded = self.encoder.fit_transform(y)
            
            print(f"ğŸ”¤ Labels codificados:")
            for i, classe in enumerate(self.encoder.classes_):
                print(f"   {classe} â†’ {i}")
            
            # Split estratificado
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_encoded, 
                test_size=self.config['test_size'],
                random_state=self.config['random_state'],
                stratify=y_encoded
            )
            
            print(f"ğŸ¯ DivisÃ£o dos dados:")
            print(f"   - Treino: {X_train.shape[0]:,} amostras ({X_train.shape[0]/len(X)*100:.1f}%)")
            print(f"   - Teste:  {X_test.shape[0]:,} amostras ({X_test.shape[0]/len(X)*100:.1f}%)")
            
            # NormalizaÃ§Ã£o
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            print("âœ… NormalizaÃ§Ã£o aplicada (StandardScaler)")
            
            return X_train_scaled, X_test_scaled, y_train, y_test
            
        except Exception as e:
            print(f"âŒ Erro ao preparar dados: {e}")
            return None
    
    def treinar_modelo(self, X_train, X_test, y_train, y_test):
        """Treinar o modelo Random Forest"""
        print("\nğŸ¤– INICIANDO TREINAMENTO DO MODELO")
        print("=" * 60)
        
        try:
            # Criar modelo
            self.modelo = RandomForestClassifier(
                n_estimators=self.config['n_estimators'],
                max_depth=self.config['max_depth'],
                min_samples_split=self.config['min_samples_split'],
                min_samples_leaf=self.config['min_samples_leaf'],
                random_state=self.config['random_state'],
                n_jobs=-1,  # Usar todos os cores
                verbose=1
            )
            
            print("ğŸ”„ Treinando modelo...")
            self.modelo.fit(X_train, y_train)
            print("âœ… Modelo treinado com sucesso!")
            
            # AvaliaÃ§Ã£o no conjunto de teste
            y_pred = self.modelo.predict(X_test)
            acuracia = accuracy_score(y_test, y_pred)
            
            print(f"\nğŸ¯ AVALIAÃ‡ÃƒO NO TESTE:")
            print(f"   AcurÃ¡cia: {acuracia:.4f} ({acuracia*100:.2f}%)")
            
            # RelatÃ³rio de classificaÃ§Ã£o
            print(f"\nğŸ“Š RELATÃ“RIO DE CLASSIFICAÃ‡ÃƒO:")
            report = classification_report(y_test, y_pred, target_names=self.encoder.classes_, output_dict=True)
            
            for classe in self.encoder.classes_:
                if classe in report:
                    prec = report[classe]['precision']
                    rec = report[classe]['recall']
                    f1 = report[classe]['f1-score']
                    print(f"   {classe:>8}: Precision {prec:.3f} | Recall {rec:.3f} | F1 {f1:.3f}")
            
            # Matriz de confusÃ£o
            print(f"\nğŸ­ MATRIZ DE CONFUSÃƒO (linha â†’ coluna):")
            cm = confusion_matrix(y_test, y_pred)
            print("     " + " ".join([f"{c:>3}" for c in self.encoder.classes_]))
            for i, true_class in enumerate(self.encoder.classes_):
                linha = f"{true_class:>3} " + " ".join([f"{cm[i,j]:>3}" for j in range(len(self.encoder.classes_))])
                print(linha)
            
            # ValidaÃ§Ã£o cruzada
            print(f"\nğŸ”„ VALIDAÃ‡ÃƒO CRUZADA ({self.config['cv_folds']}-fold):")
            cv_scores = cross_val_score(self.modelo, X_train, y_train, cv=self.config['cv_folds'])
            print(f"   Scores: {[f'{s:.4f}' for s in cv_scores]}")
            print(f"   MÃ©dia:  {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
            
            # ImportÃ¢ncia das features
            importancias = self.modelo.feature_importances_
            top_features = np.argsort(importancias)[-10:]  # Top 10
            print(f"\nğŸ“Š TOP 10 FEATURES MAIS IMPORTANTES:")
            for idx in reversed(top_features):
                print(f"   f{idx+1:2d}: {importancias[idx]:.4f}")
            
            return acuracia
            
        except Exception as e:
            print(f"âŒ Erro no treinamento: {e}")
            return 0
    
    def salvar_modelo(self, acuracia):
        """Salvar modelo no formato compatÃ­vel com app.py"""
        print("\nğŸ’¾ SALVANDO MODELO TREINADO")
        print("=" * 60)
        
        # Criar pasta de modelos (compatÃ­vel com app.py)
        pasta_modelos = 'modelos'
        if not os.path.exists(pasta_modelos):
            os.makedirs(pasta_modelos)
        
        try:
            # Salvar componentes individuais
            with open(os.path.join(pasta_modelos, 'modelo.pkl'), 'wb') as f:
                pickle.dump(self.modelo, f)
            with open(os.path.join(pasta_modelos, 'scaler.pkl'), 'wb') as f:
                pickle.dump(self.scaler, f)
            with open(os.path.join(pasta_modelos, 'encoder.pkl'), 'wb') as f:
                pickle.dump(self.encoder, f)
            
            # InformaÃ§Ãµes do modelo (compatÃ­vel com app.py)
            self.info_modelo = {
                'classes': self.encoder.classes_.tolist(),
                'accuracy': acuracia,
                'description': f"Modelo TreinadorLIBRAS - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                'model_type': 'RandomForest',
                'total_samples': self.info_dataset['amostras'],
                'features_used': 51,
                'training_date': datetime.now().isoformat(),
                'config': self.config
            }
            
            with open(os.path.join(pasta_modelos, 'info.pkl'), 'wb') as f:
                pickle.dump(self.info_modelo, f)
            
            print("âœ… MODELO SALVO COM SUCESSO!")
            print(f"ğŸ“ Pasta: {pasta_modelos}/")
            print("ğŸ“„ Arquivos salvos:")
            print("   - modelo.pkl (modelo Random Forest)")
            print("   - scaler.pkl (normalizador StandardScaler)")
            print("   - encoder.pkl (codificador de labels)")
            print("   - info.pkl (informaÃ§Ãµes do modelo)")
            print(f"\nğŸ¯ AcurÃ¡cia do modelo: {acuracia:.4f}")
            print(f"ğŸ¯ Classes treinadas: {len(self.info_modelo['classes'])}")
            print(f"ğŸ“Š Amostras utilizadas: {self.info_modelo['total_samples']:,}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Erro ao salvar modelo: {e}")
            return False
    
    def teste_compatibilidade(self):
        """Teste de compatibilidade com app.py"""
        print("\nğŸ”§ TESTE DE COMPATIBILIDADE")
        print("=" * 60)
        
        try:
            # Simular dados de entrada (51 features)
            dados_teste = np.random.random((1, 51))
            
            # Processar como no app.py
            dados_normalizados = self.scaler.transform(dados_teste)
            probabilidades = self.modelo.predict_proba(dados_normalizados)[0]
            predicao_idx = np.argmax(probabilidades)
            classe_predita = self.encoder.inverse_transform([predicao_idx])[0]
            confianca = probabilidades[predicao_idx]
            
            print("âœ… COMPATIBILIDADE VERIFICADA:")
            print(f"   - Scaler: 51 â†’ {dados_normalizados.shape[1]} features")
            print(f"   - Modelo: prediÃ§Ã£o â†’ {classe_predita}")
            print(f"   - Encoder: decodificaÃ§Ã£o funcionando")
            print(f"   - ConfianÃ§a: {confianca:.3f}")
            print(f"   - Probabilidades: shape {probabilidades.shape}")
            
            return True
            
        except Exception as e:
            print(f"âŒ FALHA NA COMPATIBILIDADE: {e}")
            return False

def main():
    print("ğŸš€ TREINADOR LIBRAS - TRADULIBRAS")
    print("=" * 70)
    print("Sistema de treinamento compatÃ­vel com app.py")
    print("=" * 70)
    
    # Inicializar treinador
    treinador = TreinadorLIBRAS()
    
    # 1. Encontrar e diagnosticar dataset
    arquivo = treinador.encontrar_dataset()
    if not treinador.diagnosticar_dataset(arquivo):
        return
    
    # 2. Preparar dados
    dados = treinador.preparar_dados()
    if dados is None:
        return
    
    X_train, X_test, y_train, y_test = dados
    
    # 3. Treinar modelo
    acuracia = treinador.treinar_modelo(X_train, X_test, y_train, y_test)
    
    # 4. Salvar se a acurÃ¡cia for aceitÃ¡vel
    if acuracia >= 0.7:  # Limiar reduzido para aceitar mais modelos
        if treinador.salvar_modelo(acuracia):
            # Teste final de compatibilidade
            if treinador.teste_compatibilidade():
                print("\nğŸ‰ TREINAMENTO CONCLUÃDO COM SUCESSO!")
                print("   O modelo estÃ¡ pronto para uso no app.py!")
                print(f"   ğŸ’¡ Execute: python app.py")
            else:
                print("\nâš ï¸  Modelo salvo mas com problemas de compatibilidade")
    else:
        print(f"\nâš ï¸  AcurÃ¡cia muito baixa ({acuracia:.3f})")
        print("ğŸ’¡ RECOMENDAÃ‡Ã•ES:")
        print("   - Colete mais dados balanceados")
        print("   - Verifique a qualidade dos gestos")
        print("   - Aumente o nÃºmero de amostras por classe")
        print("   - Melhore a iluminaÃ§Ã£o e posiÃ§Ã£o da cÃ¢mera")
    
    print("\nğŸ‘‹ Finalizado!")

if __name__ == "__main__":
    main()